import argparse
import random

from csv import CsvDataset

cl_parser = argparse.ArgumentParser( description="Creates random subsets of faults" )
cl_parser.add_argument( "input_file", type=str, nargs=1,
						help="The input file, generated by aires-summarize-episode.py" )
cl_parser.add_argument( "--name", type=str, default=None,
					  help="The root name of the dataset. Individual file names are derived from this." )
cl_parser.add_argument( "-N", type=int, default=0, help="Size of each subset" )
cl_parser.add_argument( "-k", type=int, default=1, help="Number of subsets for cross-validation" )
cl_parser.add_argument( "--seed", type=int, default=0, help="RNG seed (default: no particular seed)" )
args = cl_parser.parse_args()

if args.N == 0 and args.k != 1:
	raise RuntimeError( "If args.N == 0, then args.k must be 1" )

with open( args.input_file[0] ) as input_file:
	data = CsvDataset( input_file )
	t_blackout = data.attribute_index( "t_blackout" )
	faults = data.attribute_index( "faults" )
	recoverable_faults = []
	for fv in data.feature_vectors:
		t = int(fv[t_blackout])
		if t > 10 and t < 311:
			recoverable_faults.append( fv[faults] )
	if args.N * args.k > len(recoverable_faults):
		raise AssertionError( "Not enough faults for requested dataset size" )
	rng = random.Random()
	if args.seed != 0:
		rng.seed( args.seed )
	rng.shuffle( recoverable_faults )
	next = 0
	for i in range(0, args.k):
		filename = args.name + str(i) + ".txt"
		with open( filename, "w" ) as fold_i:
			N = len(recoverable_faults) if args.N == 0 else args.N
			for j in range(0, N):
				fold_i.write( recoverable_faults[next] + "\n" )
				next += 1
